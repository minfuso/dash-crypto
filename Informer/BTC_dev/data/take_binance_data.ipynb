{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "45e7183f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import zipfile\n",
    "import io\n",
    "import pandas as pd\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "636fbfb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL de base des archives Binance\n",
    "BASE_URL = \"https://data.binance.vision/data/spot/monthly/klines/BTCUSDT/1h/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fda86ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_month(year: int, month: int):\n",
    "    \"\"\"Télécharge les données de trading BTCUSDT pour un mois donné.\n",
    "    \n",
    "    Args:\n",
    "        year (int): Année (ex: 2023)\n",
    "        month (int): Mois (1-12)\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame contenant les données de trading, ou None si le fichier n'existe pas.\n",
    "    \"\"\"\n",
    "    fname = f\"BTCUSDT-1h-{year}-{month:02d}.zip\"\n",
    "    url = BASE_URL + fname\n",
    "    r = requests.get(url)\n",
    "    if r.status_code == 200:\n",
    "        z = zipfile.ZipFile(io.BytesIO(r.content))\n",
    "        csv_file = z.namelist()[0]\n",
    "        df = pd.read_csv(\n",
    "            z.open(csv_file), \n",
    "            header=None,\n",
    "            names=[\n",
    "                \"open_time\", \"open\", \"high\", \"low\", \"close\", \"volume\",\n",
    "                \"close_time\", \"quote_asset_volume\", \"number_of_trades\",\n",
    "                \"taker_buy_base\", \"taker_buy_quote\", \"ignore\"\n",
    "            ]\n",
    "        )\n",
    "        return df\n",
    "    else:\n",
    "        print(f\"Pas trouvé : {url}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b1d09f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dataset(start_year=2017, start_month=8, end_year=None, end_month=None, out_csv=\"BTCUSDT_1h.csv\"):\n",
    "    \"\"\"Télécharge et concatène toutes les données disponibles en un CSV unique.\"\"\"\n",
    "    if end_year is None or end_month is None:\n",
    "        now = datetime.utcnow()\n",
    "        end_year, end_month = now.year, now.month\n",
    "\n",
    "    dfs = []\n",
    "    for year in range(start_year, end_year + 1):\n",
    "        for month in range(1, 13):\n",
    "            if (year == start_year and month < start_month) or (year == end_year and month > end_month):\n",
    "                continue\n",
    "            print(f\"Téléchargement {year}-{month:02d} ...\")\n",
    "            df = download_month(year, month)\n",
    "            if df is not None:\n",
    "                dfs.append(df)\n",
    "\n",
    "    if dfs:\n",
    "        all_data = pd.concat(dfs, ignore_index=True)\n",
    "        # Conversion timestamp en datetime lisible\n",
    "        all_data[\"open_time\"] = pd.to_datetime(all_data[\"open_time\"], unit=\"ms\", errors=\"coerce\")\n",
    "        all_data[\"close_time\"] = pd.to_datetime(all_data[\"close_time\"], unit=\"ms\", errors=\"coerce\")\n",
    "        \n",
    "        # Delete corrupted rows\n",
    "        # all_data.dropna(inplace=True, subset=[\"open_time\", \"close_time\"])\n",
    "        # Sauvegarde CSV\n",
    "        all_data.to_csv(out_csv, index=False)\n",
    "        print(f\"\\n✅ Dataset sauvegardé dans {out_csv} ({len(all_data)} lignes)\")\n",
    "        return all_data\n",
    "    else:\n",
    "        print(\"❌ Aucun fichier téléchargé.\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "97229600",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_60646/123367092.py:4: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "  now = datetime.utcnow()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Téléchargement 2017-08 ...\n",
      "Téléchargement 2017-09 ...\n",
      "Téléchargement 2017-10 ...\n",
      "Téléchargement 2017-11 ...\n",
      "Téléchargement 2017-12 ...\n",
      "Téléchargement 2018-01 ...\n",
      "Téléchargement 2018-02 ...\n",
      "Téléchargement 2018-03 ...\n",
      "Téléchargement 2018-04 ...\n",
      "Téléchargement 2018-05 ...\n",
      "Téléchargement 2018-06 ...\n",
      "Téléchargement 2018-07 ...\n",
      "Téléchargement 2018-08 ...\n",
      "Téléchargement 2018-09 ...\n",
      "Téléchargement 2018-10 ...\n",
      "Téléchargement 2018-11 ...\n",
      "Téléchargement 2018-12 ...\n",
      "Téléchargement 2019-01 ...\n",
      "Téléchargement 2019-02 ...\n",
      "Téléchargement 2019-03 ...\n",
      "Téléchargement 2019-04 ...\n",
      "Téléchargement 2019-05 ...\n",
      "Téléchargement 2019-06 ...\n",
      "Téléchargement 2019-07 ...\n",
      "Téléchargement 2019-08 ...\n",
      "Téléchargement 2019-09 ...\n",
      "Téléchargement 2019-10 ...\n",
      "Téléchargement 2019-11 ...\n",
      "Téléchargement 2019-12 ...\n",
      "Téléchargement 2020-01 ...\n",
      "Téléchargement 2020-02 ...\n",
      "Téléchargement 2020-03 ...\n",
      "Téléchargement 2020-04 ...\n",
      "Téléchargement 2020-05 ...\n",
      "Téléchargement 2020-06 ...\n",
      "Téléchargement 2020-07 ...\n",
      "Téléchargement 2020-08 ...\n",
      "Téléchargement 2020-09 ...\n",
      "Téléchargement 2020-10 ...\n",
      "Téléchargement 2020-11 ...\n",
      "Téléchargement 2020-12 ...\n",
      "Téléchargement 2021-01 ...\n",
      "Téléchargement 2021-02 ...\n",
      "Téléchargement 2021-03 ...\n",
      "Téléchargement 2021-04 ...\n",
      "Téléchargement 2021-05 ...\n",
      "Téléchargement 2021-06 ...\n",
      "Téléchargement 2021-07 ...\n",
      "Téléchargement 2021-08 ...\n",
      "Téléchargement 2021-09 ...\n",
      "Téléchargement 2021-10 ...\n",
      "Téléchargement 2021-11 ...\n",
      "Téléchargement 2021-12 ...\n",
      "Téléchargement 2022-01 ...\n",
      "Téléchargement 2022-02 ...\n",
      "Téléchargement 2022-03 ...\n",
      "Téléchargement 2022-04 ...\n",
      "Téléchargement 2022-05 ...\n",
      "Téléchargement 2022-06 ...\n",
      "Téléchargement 2022-07 ...\n",
      "Téléchargement 2022-08 ...\n",
      "Téléchargement 2022-09 ...\n",
      "Téléchargement 2022-10 ...\n",
      "Téléchargement 2022-11 ...\n",
      "Téléchargement 2022-12 ...\n",
      "Téléchargement 2023-01 ...\n",
      "Téléchargement 2023-02 ...\n",
      "Téléchargement 2023-03 ...\n",
      "Téléchargement 2023-04 ...\n",
      "Téléchargement 2023-05 ...\n",
      "Téléchargement 2023-06 ...\n",
      "Téléchargement 2023-07 ...\n",
      "Téléchargement 2023-08 ...\n",
      "Téléchargement 2023-09 ...\n",
      "Téléchargement 2023-10 ...\n",
      "Téléchargement 2023-11 ...\n",
      "Téléchargement 2023-12 ...\n",
      "Téléchargement 2024-01 ...\n",
      "Téléchargement 2024-02 ...\n",
      "Téléchargement 2024-03 ...\n",
      "Téléchargement 2024-04 ...\n",
      "Téléchargement 2024-05 ...\n",
      "Téléchargement 2024-06 ...\n",
      "Téléchargement 2024-07 ...\n",
      "Téléchargement 2024-08 ...\n",
      "Téléchargement 2024-09 ...\n",
      "Téléchargement 2024-10 ...\n",
      "Téléchargement 2024-11 ...\n",
      "Téléchargement 2024-12 ...\n",
      "Téléchargement 2025-01 ...\n",
      "Téléchargement 2025-02 ...\n",
      "Téléchargement 2025-03 ...\n",
      "Téléchargement 2025-04 ...\n",
      "Téléchargement 2025-05 ...\n",
      "Téléchargement 2025-06 ...\n",
      "Téléchargement 2025-07 ...\n",
      "Téléchargement 2025-08 ...\n",
      "Téléchargement 2025-09 ...\n",
      "Pas trouvé : https://data.binance.vision/data/spot/monthly/klines/BTCUSDT/1h/BTCUSDT-1h-2025-09.zip\n",
      "\n",
      "✅ Dataset sauvegardé dans BTCUSDT_1h_full.csv (70357 lignes)\n"
     ]
    }
   ],
   "source": [
    "# Exemple d’utilisation : télécharger toutes les données depuis août 2017\n",
    "df = build_dataset(start_year=2017, start_month=8, out_csv=\"BTCUSDT_1h_full.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b2197500",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de doublons dans open_time : 5831\n",
      "Nombre de doublons dans open_time : 0\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 64526 entries, 0 to 64525\n",
      "Data columns (total 12 columns):\n",
      " #   Column              Non-Null Count  Dtype         \n",
      "---  ------              --------------  -----         \n",
      " 0   open_time           64525 non-null  datetime64[ns]\n",
      " 1   open                64526 non-null  float64       \n",
      " 2   high                64526 non-null  float64       \n",
      " 3   low                 64526 non-null  float64       \n",
      " 4   close               64526 non-null  float64       \n",
      " 5   volume              64526 non-null  float64       \n",
      " 6   close_time          64525 non-null  datetime64[ns]\n",
      " 7   quote_asset_volume  64526 non-null  float64       \n",
      " 8   number_of_trades    64526 non-null  int64         \n",
      " 9   taker_buy_base      64526 non-null  float64       \n",
      " 10  taker_buy_quote     64526 non-null  float64       \n",
      " 11  ignore              64526 non-null  float64       \n",
      "dtypes: datetime64[ns](2), float64(9), int64(1)\n",
      "memory usage: 6.4 MB\n"
     ]
    }
   ],
   "source": [
    "duplicates = df[\"open_time\"].duplicated().sum()\n",
    "print(f\"Nombre de doublons dans open_time : {duplicates}\")\n",
    "\n",
    "df = df.drop_duplicates(subset=[\"open_time\"], keep=\"first\")\n",
    "\n",
    "duplicates = df[\"open_time\"].duplicated().sum()\n",
    "print(f\"Nombre de doublons dans open_time : {duplicates}\")\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ee699f54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 64652 entries, 2017-08-17 04:00:00 to 2024-12-31 23:00:00\n",
      "Freq: h\n",
      "Data columns (total 11 columns):\n",
      " #   Column              Non-Null Count  Dtype         \n",
      "---  ------              --------------  -----         \n",
      " 0   open                64482 non-null  float64       \n",
      " 1   high                64482 non-null  float64       \n",
      " 2   low                 64482 non-null  float64       \n",
      " 3   close               64482 non-null  float64       \n",
      " 4   volume              64482 non-null  float64       \n",
      " 5   close_time          64482 non-null  datetime64[ns]\n",
      " 6   quote_asset_volume  64482 non-null  float64       \n",
      " 7   number_of_trades    64482 non-null  float64       \n",
      " 8   taker_buy_base      64482 non-null  float64       \n",
      " 9   taker_buy_quote     64482 non-null  float64       \n",
      " 10  ignore              64482 non-null  float64       \n",
      "dtypes: datetime64[ns](1), float64(10)\n",
      "memory usage: 5.9 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_60646/2554304782.py:3: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  full_range = pd.date_range(df.index.min(), df.index.max(), freq=\"H\")\n"
     ]
    }
   ],
   "source": [
    "df = df.set_index(\"open_time\").sort_index()\n",
    "\n",
    "full_range = pd.date_range(df.index.min(), df.index.max(), freq=\"H\")\n",
    "df = df.reindex(full_range)\n",
    "\n",
    "df.index.name = \"open_time\"\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba980f49",
   "metadata": {},
   "source": [
    "## Add and transform for usefull features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e6c1cce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_rsi(series, window=14):\n",
    "    delta = series.diff()\n",
    "    gain = (delta.where(delta > 0, 0)).fillna(0)\n",
    "    loss = (-delta.where(delta < 0, 0)).fillna(0)\n",
    "\n",
    "    avg_gain = gain.rolling(window=window).mean()\n",
    "    avg_loss = loss.rolling(window=window).mean()\n",
    "\n",
    "    rs = avg_gain / avg_loss\n",
    "    rsi = 100 - (100 / (1 + rs))\n",
    "    return rsi\n",
    "\n",
    "def compute_features(df):\n",
    "    df = df.copy()\n",
    "    \n",
    "    # SMA\n",
    "    df[\"sma_7d\"] = df[\"close\"].rolling(window=7*24).mean()\n",
    "    df[\"sma_30d\"] = df[\"close\"].rolling(window=30*24).mean()\n",
    "    df[\"sma_50d\"] = df[\"close\"].rolling(window=50*24).mean()\n",
    "    df[\"sma_100d\"] = df[\"close\"].rolling(window=100*24).mean()\n",
    "    \n",
    "    # Volatibility\n",
    "    df[\"return\"] = df[\"close\"].pct_change()\n",
    "\n",
    "    # Volatility on 20 hours\n",
    "    df[\"volatility_20\"] = df[\"return\"].rolling(window=20).std()\n",
    "    df[\"volatility_50\"] = df[\"return\"].rolling(window=50).std()\n",
    "    df[\"volatility_100\"] = df[\"return\"].rolling(window=100).std()\n",
    "    df[\"volatility_14d\"] = df[\"return\"].rolling(window=14*24).std()\n",
    "    \n",
    "    # RSI 14 and 14 days\n",
    "    df[\"rsi_14\"] = compute_rsi(df[\"close\"], window=14)\n",
    "    df[\"rsi_14d\"] = compute_rsi(df[\"close\"], window=14*24)\n",
    "    \n",
    "    # MACD\n",
    "    df = compute_MACD(df)\n",
    "    \n",
    "    # Relative volume 20\n",
    "    df[\"volume_sma20\"] = df[\"volume\"].rolling(window=20).mean()\n",
    "    df[\"volume_sma20d\"] = df[\"volume\"].rolling(window=20*24).mean()\n",
    "    df[\"volume_rel20\"] = df[\"volume\"] / df[\"volume_sma20\"]\n",
    "    df[\"volume_rel20d\"] = df[\"volume\"] / df[\"volume_sma20d\"]\n",
    "    \n",
    "    return df\n",
    "\n",
    "def compute_MACD(df):\n",
    "    df = df.copy()\n",
    "    \n",
    "    # EMA 12 et EMA 26\n",
    "    df[\"ema_12d\"] = df[\"close\"].ewm(span=12*24, adjust=False).mean()\n",
    "    df[\"ema_26d\"] = df[\"close\"].ewm(span=26*24, adjust=False).mean()\n",
    "    \n",
    "    # MACD line\n",
    "    df[\"MACD\"] = df[\"ema_12d\"] - df[\"ema_26d\"]\n",
    "\n",
    "    # Signal line (EMA 9 du MACD)\n",
    "    df[\"Signal\"] = df[\"MACD\"].ewm(span=9*24, adjust=False).mean()\n",
    "\n",
    "    # Histogramme\n",
    "    df[\"MACD_Hist\"] = df[\"MACD\"] - df[\"Signal\"]\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6c3d767c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 64652 entries, 2017-08-17 04:00:00 to 2024-12-31 23:00:00\n",
      "Freq: h\n",
      "Data columns (total 31 columns):\n",
      " #   Column              Non-Null Count  Dtype         \n",
      "---  ------              --------------  -----         \n",
      " 0   open                64482 non-null  float64       \n",
      " 1   high                64482 non-null  float64       \n",
      " 2   low                 64482 non-null  float64       \n",
      " 3   close               64482 non-null  float64       \n",
      " 4   volume              64482 non-null  float64       \n",
      " 5   close_time          64482 non-null  datetime64[ns]\n",
      " 6   quote_asset_volume  64482 non-null  float64       \n",
      " 7   number_of_trades    64482 non-null  float64       \n",
      " 8   taker_buy_base      64482 non-null  float64       \n",
      " 9   taker_buy_quote     64482 non-null  float64       \n",
      " 10  ignore              64482 non-null  float64       \n",
      " 11  sma_7d              59926 non-null  float64       \n",
      " 12  sma_30d             48125 non-null  float64       \n",
      " 13  sma_50d             40084 non-null  float64       \n",
      " 14  sma_100d            27203 non-null  float64       \n",
      " 15  return              64651 non-null  float64       \n",
      " 16  volatility_20       64632 non-null  float64       \n",
      " 17  volatility_50       64602 non-null  float64       \n",
      " 18  volatility_100      64552 non-null  float64       \n",
      " 19  volatility_14d      64316 non-null  float64       \n",
      " 20  rsi_14              64576 non-null  float64       \n",
      " 21  rsi_14d             64317 non-null  float64       \n",
      " 22  ema_12d             64652 non-null  float64       \n",
      " 23  ema_26d             64652 non-null  float64       \n",
      " 24  MACD                64652 non-null  float64       \n",
      " 25  Signal              64652 non-null  float64       \n",
      " 26  MACD_Hist           64652 non-null  float64       \n",
      " 27  volume_sma20        63931 non-null  float64       \n",
      " 28  volume_sma20d       52699 non-null  float64       \n",
      " 29  volume_rel20        63931 non-null  float64       \n",
      " 30  volume_rel20d       52699 non-null  float64       \n",
      "dtypes: datetime64[ns](1), float64(30)\n",
      "memory usage: 15.8 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_60646/768829287.py:23: FutureWarning: The default fill_method='pad' in Series.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  df[\"return\"] = df[\"close\"].pct_change()\n"
     ]
    }
   ],
   "source": [
    "df = compute_features(df)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a74deff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_dataset(df):\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Colonnes inutiles\n",
    "    drop_cols = [\n",
    "        \"close_time\", \"ignore\", \n",
    "        \"ema_12d\", \"ema_26d\", \n",
    "        \"volume_sma20\", \"volume_sma20d\"\n",
    "    ]\n",
    "    \n",
    "    df = df.drop(columns=[c for c in drop_cols if c in df.columns])\n",
    "    \n",
    "    # Suppression des lignes avec NaN restants\n",
    "    df = df.dropna()\n",
    "    \n",
    "    print(f\"✅ Dataset nettoyé : {df.shape[0]} lignes, {df.shape[1]} colonnes\")\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0b69db15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Dataset nettoyé : 27203 lignes, 25 colonnes\n"
     ]
    }
   ],
   "source": [
    "cleaned_df = clean_dataset(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d08dd76d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 27203 entries, 2017-12-15 22:00:00 to 2024-12-31 23:00:00\n",
      "Data columns (total 25 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   open                27203 non-null  float64\n",
      " 1   high                27203 non-null  float64\n",
      " 2   low                 27203 non-null  float64\n",
      " 3   close               27203 non-null  float64\n",
      " 4   volume              27203 non-null  float64\n",
      " 5   quote_asset_volume  27203 non-null  float64\n",
      " 6   number_of_trades    27203 non-null  float64\n",
      " 7   taker_buy_base      27203 non-null  float64\n",
      " 8   taker_buy_quote     27203 non-null  float64\n",
      " 9   sma_7d              27203 non-null  float64\n",
      " 10  sma_30d             27203 non-null  float64\n",
      " 11  sma_50d             27203 non-null  float64\n",
      " 12  sma_100d            27203 non-null  float64\n",
      " 13  return              27203 non-null  float64\n",
      " 14  volatility_20       27203 non-null  float64\n",
      " 15  volatility_50       27203 non-null  float64\n",
      " 16  volatility_100      27203 non-null  float64\n",
      " 17  volatility_14d      27203 non-null  float64\n",
      " 18  rsi_14              27203 non-null  float64\n",
      " 19  rsi_14d             27203 non-null  float64\n",
      " 20  MACD                27203 non-null  float64\n",
      " 21  Signal              27203 non-null  float64\n",
      " 22  MACD_Hist           27203 non-null  float64\n",
      " 23  volume_rel20        27203 non-null  float64\n",
      " 24  volume_rel20d       27203 non-null  float64\n",
      "dtypes: float64(25)\n",
      "memory usage: 5.4 MB\n"
     ]
    }
   ],
   "source": [
    "cleaned_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3c69403a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_df.to_parquet(\"BTC_features_clean.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "16b8a1cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def make_windows(df, input_len=168, output_horizons=[1, 6, 12, 24, 168], target_col=\"close\"):\n",
    "    \"\"\"\n",
    "    Génère les fenêtres (X, Y) pour l'entraînement d'un modèle séquentiel.\n",
    "    \n",
    "    df : DataFrame Pandas (index = datetime, colonnes = features)\n",
    "    input_len : longueur de la fenêtre d'entrée (en heures)\n",
    "    output_horizons : horizons de prédiction (en heures)\n",
    "    target_col : colonne de référence pour la target (ex. 'close')\n",
    "    \n",
    "    Retourne :\n",
    "        X : np.array (n_samples, input_len, n_features)\n",
    "        Y : np.array (n_samples, len(output_horizons))\n",
    "    \"\"\"\n",
    "    data = df.values\n",
    "    target = df[target_col].values\n",
    "    n_features = data.shape[1]\n",
    "\n",
    "    X, Y = [], []\n",
    "    max_h = max(output_horizons)\n",
    "\n",
    "    for t in range(len(df) - input_len - max_h):\n",
    "        # Fenêtre d'entrée\n",
    "        x_window = data[t : t + input_len]\n",
    "\n",
    "        # Targets en rendements relatifs\n",
    "        y_window = []\n",
    "        current_price = target[t + input_len - 1]\n",
    "        for h in output_horizons:\n",
    "            future_price = target[t + input_len + h - 1]\n",
    "            y_window.append(future_price / current_price - 1)\n",
    "\n",
    "        X.append(x_window)\n",
    "        Y.append(y_window)\n",
    "\n",
    "    X = np.array(X, dtype=np.float32)\n",
    "    Y = np.array(Y, dtype=np.float32)\n",
    "\n",
    "    print(f\"✅ make_windows: X={X.shape}, Y={Y.shape}\")\n",
    "    return X, Y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b72450a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ make_windows: X=(26867, 168, 25), Y=(26867, 5)\n"
     ]
    }
   ],
   "source": [
    "X, Y, = make_windows(cleaned_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd0605d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dash-crypto",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
