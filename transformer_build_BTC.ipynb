{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c0c8f15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['open', 'high', 'low', 'close', 'volume', 'quote_asset_volume',\n",
       "       'nb_trades', 'taker_buy_base', 'taker_buy_quote', 'sma_7', 'sma_30',\n",
       "       'sma_50', 'sma_100', 'return', 'volatility_20', 'rsi_14', 'ema_12',\n",
       "       'ema_26', 'MACD', 'Signal', 'MACD_Hist', 'volume_sma20', 'volume_rel',\n",
       "       'hour', 'weekday', 'future_close_1h', 'future_close_3h',\n",
       "       'future_close_6h', 'target_1h', 'target_3h', 'target_6h'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# 1) Charger ton CSV\n",
    "df = pd.read_csv(\"BTC_features.csv\")\n",
    "\n",
    "# Convertir open_time en datetime\n",
    "df[\"open_time\"] = pd.to_datetime(df[\"open_time\"])\n",
    "\n",
    "# Extraire des features temporelles\n",
    "df[\"hour\"] = df[\"open_time\"].dt.hour\n",
    "df[\"weekday\"] = df[\"open_time\"].dt.weekday\n",
    "\n",
    "# Supprimer colonnes inutiles\n",
    "drop_cols = [\"open_time\", \"close_time\", \"ignore\"]\n",
    "df = df.drop(columns=drop_cols, errors=\"ignore\")\n",
    "\n",
    "# Créer plusieurs horizons\n",
    "df[\"future_close_1h\"] = df[\"close\"].shift(-1)\n",
    "df[\"future_close_3h\"] = df[\"close\"].shift(-3)\n",
    "df[\"future_close_6h\"] = df[\"close\"].shift(-6)\n",
    "\n",
    "# Créer les cibles binaires\n",
    "df[\"target_1h\"] = (df[\"future_close_1h\"] > df[\"close\"]).astype(int)\n",
    "df[\"target_3h\"] = (df[\"future_close_3h\"] > df[\"close\"]).astype(int)\n",
    "df[\"target_6h\"] = (df[\"future_close_6h\"] > df[\"close\"]).astype(int)\n",
    "\n",
    "# Supprimer les NaN de fin (car pas de future_close possible)\n",
    "df = df.dropna().reset_index(drop=True)\n",
    "\n",
    "# Création des features\n",
    "feature_cols = [c for c in df.columns if not c.startswith(\"future_close\") and not c.startswith(\"target\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cbc1f70e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>quote_asset_volume</th>\n",
       "      <th>nb_trades</th>\n",
       "      <th>taker_buy_base</th>\n",
       "      <th>taker_buy_quote</th>\n",
       "      <th>sma_7</th>\n",
       "      <th>...</th>\n",
       "      <th>rsi_14</th>\n",
       "      <th>ema_12</th>\n",
       "      <th>ema_26</th>\n",
       "      <th>MACD</th>\n",
       "      <th>Signal</th>\n",
       "      <th>MACD_Hist</th>\n",
       "      <th>volume_sma20</th>\n",
       "      <th>volume_rel</th>\n",
       "      <th>hour</th>\n",
       "      <th>weekday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.893539</td>\n",
       "      <td>-1.910873</td>\n",
       "      <td>-1.961360</td>\n",
       "      <td>-1.960006</td>\n",
       "      <td>0.425378</td>\n",
       "      <td>0.253619</td>\n",
       "      <td>1.295537</td>\n",
       "      <td>0.153082</td>\n",
       "      <td>0.016896</td>\n",
       "      <td>-1.999246</td>\n",
       "      <td>...</td>\n",
       "      <td>0.253246</td>\n",
       "      <td>-2.010290</td>\n",
       "      <td>-2.058358</td>\n",
       "      <td>0.727614</td>\n",
       "      <td>0.753003</td>\n",
       "      <td>0.067199</td>\n",
       "      <td>-0.074530</td>\n",
       "      <td>0.529623</td>\n",
       "      <td>0.504309</td>\n",
       "      <td>0.487024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.958215</td>\n",
       "      <td>-1.927586</td>\n",
       "      <td>-1.920676</td>\n",
       "      <td>-1.957143</td>\n",
       "      <td>0.257680</td>\n",
       "      <td>0.106517</td>\n",
       "      <td>0.640438</td>\n",
       "      <td>-0.093245</td>\n",
       "      <td>-0.199598</td>\n",
       "      <td>-1.982622</td>\n",
       "      <td>...</td>\n",
       "      <td>0.284012</td>\n",
       "      <td>-2.001956</td>\n",
       "      <td>-2.050496</td>\n",
       "      <td>0.734950</td>\n",
       "      <td>0.758752</td>\n",
       "      <td>0.073469</td>\n",
       "      <td>-0.069913</td>\n",
       "      <td>0.318711</td>\n",
       "      <td>0.648590</td>\n",
       "      <td>0.487024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.955354</td>\n",
       "      <td>-1.981576</td>\n",
       "      <td>-1.962838</td>\n",
       "      <td>-1.948809</td>\n",
       "      <td>-0.282683</td>\n",
       "      <td>-0.375047</td>\n",
       "      <td>0.283800</td>\n",
       "      <td>-0.329895</td>\n",
       "      <td>-0.411339</td>\n",
       "      <td>-1.971248</td>\n",
       "      <td>...</td>\n",
       "      <td>0.209513</td>\n",
       "      <td>-1.993620</td>\n",
       "      <td>-2.042598</td>\n",
       "      <td>0.741755</td>\n",
       "      <td>0.764802</td>\n",
       "      <td>0.077112</td>\n",
       "      <td>-0.037421</td>\n",
       "      <td>-0.362836</td>\n",
       "      <td>0.792871</td>\n",
       "      <td>0.487024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.947025</td>\n",
       "      <td>-1.952928</td>\n",
       "      <td>-1.946996</td>\n",
       "      <td>-1.984639</td>\n",
       "      <td>-0.489922</td>\n",
       "      <td>-0.557231</td>\n",
       "      <td>-0.124850</td>\n",
       "      <td>-0.462546</td>\n",
       "      <td>-0.527410</td>\n",
       "      <td>-1.965898</td>\n",
       "      <td>...</td>\n",
       "      <td>0.145459</td>\n",
       "      <td>-1.992085</td>\n",
       "      <td>-2.037944</td>\n",
       "      <td>0.693716</td>\n",
       "      <td>0.759406</td>\n",
       "      <td>-0.061859</td>\n",
       "      <td>-0.026586</td>\n",
       "      <td>-0.617922</td>\n",
       "      <td>0.937151</td>\n",
       "      <td>0.487024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.982834</td>\n",
       "      <td>-2.020363</td>\n",
       "      <td>-2.006794</td>\n",
       "      <td>-2.022825</td>\n",
       "      <td>-0.137315</td>\n",
       "      <td>-0.248920</td>\n",
       "      <td>-0.204922</td>\n",
       "      <td>-0.273494</td>\n",
       "      <td>-0.363556</td>\n",
       "      <td>-1.971608</td>\n",
       "      <td>...</td>\n",
       "      <td>0.132370</td>\n",
       "      <td>-1.996669</td>\n",
       "      <td>-2.036468</td>\n",
       "      <td>0.600357</td>\n",
       "      <td>0.735197</td>\n",
       "      <td>-0.290282</td>\n",
       "      <td>0.008102</td>\n",
       "      <td>-0.211713</td>\n",
       "      <td>1.081432</td>\n",
       "      <td>0.487024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2890</th>\n",
       "      <td>-0.093337</td>\n",
       "      <td>-0.120347</td>\n",
       "      <td>-0.089407</td>\n",
       "      <td>-0.087806</td>\n",
       "      <td>-0.363272</td>\n",
       "      <td>-0.367031</td>\n",
       "      <td>-0.447521</td>\n",
       "      <td>-0.288705</td>\n",
       "      <td>-0.292925</td>\n",
       "      <td>-0.169292</td>\n",
       "      <td>...</td>\n",
       "      <td>1.168550</td>\n",
       "      <td>-0.169444</td>\n",
       "      <td>-0.168102</td>\n",
       "      <td>-0.021743</td>\n",
       "      <td>-0.361301</td>\n",
       "      <td>1.026445</td>\n",
       "      <td>-1.069887</td>\n",
       "      <td>0.438842</td>\n",
       "      <td>-1.515619</td>\n",
       "      <td>1.486979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2891</th>\n",
       "      <td>-0.087162</td>\n",
       "      <td>-0.126602</td>\n",
       "      <td>-0.084700</td>\n",
       "      <td>-0.119395</td>\n",
       "      <td>-0.726084</td>\n",
       "      <td>-0.727559</td>\n",
       "      <td>-0.902705</td>\n",
       "      <td>-0.769286</td>\n",
       "      <td>-0.769759</td>\n",
       "      <td>-0.160527</td>\n",
       "      <td>...</td>\n",
       "      <td>0.874315</td>\n",
       "      <td>-0.161225</td>\n",
       "      <td>-0.163900</td>\n",
       "      <td>0.040177</td>\n",
       "      <td>-0.280722</td>\n",
       "      <td>0.982082</td>\n",
       "      <td>-1.086064</td>\n",
       "      <td>-0.437976</td>\n",
       "      <td>-1.371339</td>\n",
       "      <td>1.486979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2892</th>\n",
       "      <td>-0.118732</td>\n",
       "      <td>-0.135966</td>\n",
       "      <td>-0.086547</td>\n",
       "      <td>-0.119554</td>\n",
       "      <td>-0.603844</td>\n",
       "      <td>-0.606263</td>\n",
       "      <td>-0.779926</td>\n",
       "      <td>-0.381186</td>\n",
       "      <td>-0.384939</td>\n",
       "      <td>-0.147798</td>\n",
       "      <td>...</td>\n",
       "      <td>1.044332</td>\n",
       "      <td>-0.154295</td>\n",
       "      <td>-0.160021</td>\n",
       "      <td>0.087213</td>\n",
       "      <td>-0.206237</td>\n",
       "      <td>0.908084</td>\n",
       "      <td>-1.144897</td>\n",
       "      <td>-0.056691</td>\n",
       "      <td>-1.227058</td>\n",
       "      <td>1.486979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2893</th>\n",
       "      <td>-0.118892</td>\n",
       "      <td>-0.158759</td>\n",
       "      <td>-0.162971</td>\n",
       "      <td>-0.182615</td>\n",
       "      <td>-0.437734</td>\n",
       "      <td>-0.443760</td>\n",
       "      <td>-0.655826</td>\n",
       "      <td>-0.574486</td>\n",
       "      <td>-0.578540</td>\n",
       "      <td>-0.142765</td>\n",
       "      <td>...</td>\n",
       "      <td>0.161897</td>\n",
       "      <td>-0.158145</td>\n",
       "      <td>-0.161108</td>\n",
       "      <td>0.044643</td>\n",
       "      <td>-0.155719</td>\n",
       "      <td>0.617067</td>\n",
       "      <td>-1.126448</td>\n",
       "      <td>0.350801</td>\n",
       "      <td>-1.082778</td>\n",
       "      <td>1.486979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2894</th>\n",
       "      <td>-0.181913</td>\n",
       "      <td>-0.222890</td>\n",
       "      <td>-0.177684</td>\n",
       "      <td>-0.191817</td>\n",
       "      <td>-0.614745</td>\n",
       "      <td>-0.619644</td>\n",
       "      <td>-0.803899</td>\n",
       "      <td>-0.641757</td>\n",
       "      <td>-0.645558</td>\n",
       "      <td>-0.137776</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.220221</td>\n",
       "      <td>-0.162820</td>\n",
       "      <td>-0.162798</td>\n",
       "      <td>-0.001366</td>\n",
       "      <td>-0.125107</td>\n",
       "      <td>0.375356</td>\n",
       "      <td>-1.125270</td>\n",
       "      <td>-0.111459</td>\n",
       "      <td>-0.938497</td>\n",
       "      <td>1.486979</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2895 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          open      high       low     close    volume  quote_asset_volume  \\\n",
       "0    -1.893539 -1.910873 -1.961360 -1.960006  0.425378            0.253619   \n",
       "1    -1.958215 -1.927586 -1.920676 -1.957143  0.257680            0.106517   \n",
       "2    -1.955354 -1.981576 -1.962838 -1.948809 -0.282683           -0.375047   \n",
       "3    -1.947025 -1.952928 -1.946996 -1.984639 -0.489922           -0.557231   \n",
       "4    -1.982834 -2.020363 -2.006794 -2.022825 -0.137315           -0.248920   \n",
       "...        ...       ...       ...       ...       ...                 ...   \n",
       "2890 -0.093337 -0.120347 -0.089407 -0.087806 -0.363272           -0.367031   \n",
       "2891 -0.087162 -0.126602 -0.084700 -0.119395 -0.726084           -0.727559   \n",
       "2892 -0.118732 -0.135966 -0.086547 -0.119554 -0.603844           -0.606263   \n",
       "2893 -0.118892 -0.158759 -0.162971 -0.182615 -0.437734           -0.443760   \n",
       "2894 -0.181913 -0.222890 -0.177684 -0.191817 -0.614745           -0.619644   \n",
       "\n",
       "      nb_trades  taker_buy_base  taker_buy_quote     sma_7  ...    rsi_14  \\\n",
       "0      1.295537        0.153082         0.016896 -1.999246  ...  0.253246   \n",
       "1      0.640438       -0.093245        -0.199598 -1.982622  ...  0.284012   \n",
       "2      0.283800       -0.329895        -0.411339 -1.971248  ...  0.209513   \n",
       "3     -0.124850       -0.462546        -0.527410 -1.965898  ...  0.145459   \n",
       "4     -0.204922       -0.273494        -0.363556 -1.971608  ...  0.132370   \n",
       "...         ...             ...              ...       ...  ...       ...   \n",
       "2890  -0.447521       -0.288705        -0.292925 -0.169292  ...  1.168550   \n",
       "2891  -0.902705       -0.769286        -0.769759 -0.160527  ...  0.874315   \n",
       "2892  -0.779926       -0.381186        -0.384939 -0.147798  ...  1.044332   \n",
       "2893  -0.655826       -0.574486        -0.578540 -0.142765  ...  0.161897   \n",
       "2894  -0.803899       -0.641757        -0.645558 -0.137776  ... -0.220221   \n",
       "\n",
       "        ema_12    ema_26      MACD    Signal  MACD_Hist  volume_sma20  \\\n",
       "0    -2.010290 -2.058358  0.727614  0.753003   0.067199     -0.074530   \n",
       "1    -2.001956 -2.050496  0.734950  0.758752   0.073469     -0.069913   \n",
       "2    -1.993620 -2.042598  0.741755  0.764802   0.077112     -0.037421   \n",
       "3    -1.992085 -2.037944  0.693716  0.759406  -0.061859     -0.026586   \n",
       "4    -1.996669 -2.036468  0.600357  0.735197  -0.290282      0.008102   \n",
       "...        ...       ...       ...       ...        ...           ...   \n",
       "2890 -0.169444 -0.168102 -0.021743 -0.361301   1.026445     -1.069887   \n",
       "2891 -0.161225 -0.163900  0.040177 -0.280722   0.982082     -1.086064   \n",
       "2892 -0.154295 -0.160021  0.087213 -0.206237   0.908084     -1.144897   \n",
       "2893 -0.158145 -0.161108  0.044643 -0.155719   0.617067     -1.126448   \n",
       "2894 -0.162820 -0.162798 -0.001366 -0.125107   0.375356     -1.125270   \n",
       "\n",
       "      volume_rel      hour   weekday  \n",
       "0       0.529623  0.504309  0.487024  \n",
       "1       0.318711  0.648590  0.487024  \n",
       "2      -0.362836  0.792871  0.487024  \n",
       "3      -0.617922  0.937151  0.487024  \n",
       "4      -0.211713  1.081432  0.487024  \n",
       "...          ...       ...       ...  \n",
       "2890    0.438842 -1.515619  1.486979  \n",
       "2891   -0.437976 -1.371339  1.486979  \n",
       "2892   -0.056691 -1.227058  1.486979  \n",
       "2893    0.350801 -1.082778  1.486979  \n",
       "2894   -0.111459 -0.938497  1.486979  \n",
       "\n",
       "[2895 rows x 25 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Normalisation des features\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "df[feature_cols] = scaler.fit_transform(df[feature_cols])\n",
    "df[feature_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "00821331",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (2871, 24, 25)\n",
      "y shape: (2871, 3)\n"
     ]
    }
   ],
   "source": [
    "def make_sequences_multi(data, seq_len=24, targets=[\"target_1h\",\"target_3h\",\"target_6h\"]):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - seq_len):\n",
    "        X.append(data.iloc[i:i+seq_len][feature_cols].values)\n",
    "        y.append(data.iloc[i+seq_len][targets].values)  # 3 targets\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "SEQ_LEN = 24\n",
    "X, y = make_sequences_multi(df, seq_len=SEQ_LEN)\n",
    "\n",
    "print(\"X shape:\", X.shape)  # (n_samples, 24, n_features)\n",
    "print(\"y shape:\", y.shape)  # (n_samples, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7baffe4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (2009, 24, 25) (2009, 3)\n",
      "Val: (430, 24, 25) (430, 3)\n",
      "Test: (432, 24, 25) (432, 3)\n"
     ]
    }
   ],
   "source": [
    "# Split temporel\n",
    "# Définir les tailles\n",
    "n = len(X)\n",
    "train_size = int(n * 0.7)\n",
    "val_size = int(n * 0.15)\n",
    "\n",
    "# Découpage temporel\n",
    "X_train, y_train = X[:train_size], y[:train_size]\n",
    "X_val, y_val = X[train_size:train_size+val_size], y[train_size:train_size+val_size]\n",
    "X_test, y_test = X[train_size+val_size:], y[train_size+val_size:]\n",
    "\n",
    "print(\"Train:\", X_train.shape, y_train.shape)\n",
    "print(\"Val:\", X_val.shape, y_val.shape)\n",
    "print(\"Test:\", X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6971001",
   "metadata": {},
   "source": [
    "## Étape 1 — Embedding & Positional Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96f7f243",
   "metadata": {},
   "source": [
    "On commence par créer l'input embedding. L'idée est de faire une couche qui prend les 24h et les 25 features. On doit ajouter la dimension de l'embedding, ici 128, qui transformera mes 25 features en 128 nombres.\n",
    "\n",
    "`inputs` correspond à un “**placeholder**” qui dit : j’attendrai un batch de shape `(None, 24, 25)`\n",
    "\n",
    "`x` correspond à un **objet symbolique** (KerasTensor), une sorte de **plan de calcul**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f07449",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-31 12:50:31.604271: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1756644636.400133   25878 gpu_device.cc:2020] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9709 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060, pci bus id: 0000:26:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, 24, 128)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Création de l'input embedding\n",
    "inputs = layers.Input(shape=(24, 25))  # 24h, 25 features\n",
    "x = layers.Dense(128)(inputs)  # projection\n",
    "x.shape  # (None, 24, 128)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54f6d3b9",
   "metadata": {},
   "source": [
    "On va coder le positional embedding.\n",
    "\n",
    "- `max_len=500`: taille maximale de la séquence. Peut aller jusqu'à 500, même si on va utiliser 24 (24h)\n",
    "- `d_model`: dimmension de l'embedding. Chaque position est représentée par un vecteur de 128 valeurs.\n",
    "- `pos`: Vecteur de position, allant de 0 à 499 en colonne. Permet d'avoir jusqu'à 500 séquences.\n",
    "- `i`: index des dimmensions, un vecteur allant de 0 à 127, contenant toutes les dimensions de l'embedding (128).\n",
    "\n",
    "La formule est la suivante:\n",
    "\n",
    "$$\n",
    "PE_{pos, 2i} = \\sin{\\left( \\frac{pos}{10000^{2i/d_{model}}} \\right)}, \\ PE_{pos, 2i+1} = \\cos{\\left( \\frac{pos}{10000^{2i/d_{model}}} \\right)}\n",
    "$$\n",
    "Pour les `i` pairs, on utilise la formule de gauche. Pour les `i` impairs, celle de droite. Cette partie est codée à partir de `angle_rates` jusqu'à `pe[:, 1::2]`.\n",
    "\n",
    "Ensuite, on ajoute la dimension des batchs à `self.pos_encoding`, transformant la matrice en tenseur de dimension 3. La dimension ajouté sers à utiliser des batchs.\n",
    "\n",
    "Dans le `call`, on prend la taille de la séquence de notre input avec `seq_len`. C'est 24 dans mon cas pour 24h. Enfin, on l'ajoute à notre input pour avoir le résultat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac6bce8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class SinePositionalEncoding(layers.Layer):\n",
    "    def __init__(self, max_len=500, d_model=128):\n",
    "        super().__init__()\n",
    "        pos = np.arange(max_len)[:, None]  # shape (max_len, 1)\n",
    "        i = np.arange(d_model)[None, :]    # shape (1, d_model)\n",
    "\n",
    "        angle_rates = 1 / np.power(10000, (2*(i//2)) / np.float32(d_model))\n",
    "        angles = pos * angle_rates\n",
    "\n",
    "        # tableau (max_len, d_model)\n",
    "        pe = np.zeros((max_len, d_model))\n",
    "        pe[:, 0::2] = np.sin(angles[:, 0::2])  # pairs\n",
    "        pe[:, 1::2] = np.cos(angles[:, 1::2])  # impairs\n",
    "\n",
    "        # on stocke comme constante TensorFlow\n",
    "        self.pos_encoding = tf.constant(pe[None, ...], dtype=tf.float32)  # (1, max_len, d_model)\n",
    "\n",
    "    def call(self, x):\n",
    "        seq_len = tf.shape(x)[1]\n",
    "        return x + self.pos_encoding[:, :seq_len, :]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dash-crypto",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
